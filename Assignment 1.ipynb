{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d71c3e6",
   "metadata": {},
   "source": [
    "1. What is the function of a summation junction of a neuron? What is threshold activation\n",
    "function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a56f4",
   "metadata": {},
   "source": [
    "summation, in physiology, the additive effect of several electrical impulses on a neuromuscular junction, the junction between a nerve cell and a muscle cell. Individually the stimuli cannot evoke a response, but collectively they can generate a response.\n",
    "Binary Step Activation Function. Binary step function is a threshold-based activation function which means after a certain threshold neuron is activated and below the said threshold neuron is deactivated. In the above graph, the threshold is zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5963ad0a",
   "metadata": {},
   "source": [
    "2. What is a step function? What is the difference of step function with threshold function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309eb147",
   "metadata": {},
   "source": [
    "Binary Step Activation Function. Binary step function is a threshold-based activation function which means after a certain threshold neuron is activated and below the said threshold neuron is deactivated. In the above graph, the threshold is zero.Activation functions are decision making units of neural networks. They calculates net output of a neural node. Herein, heaviside step function is one of the most common activation function in neural networks. The function produces binary output. That is the reason why it also called as binary step function. The function produces 1 (or true) when input passes threshold limit whereas it produces 0 (or false) when input does not pass threshold. That’s why, they are very useful for binary classification studies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d251a40a",
   "metadata": {},
   "source": [
    "3. Explain the McCulloch–Pitts model of neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8ea47",
   "metadata": {},
   "source": [
    "The McCulloch-Pitts model was an extremely simple artificial neuron. The inputs could be either a zero or a one. And the output was a zero or a one. And each input could be either excitatory or inhibitory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11f8d55",
   "metadata": {},
   "source": [
    "4. Explain the ADALINE network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96271a4",
   "metadata": {},
   "source": [
    "ADALINE (Adaptive Linear Neuron or later Adaptive Linear Element) is an early single-layer artificial neural network and the name of the physical device that implemented this network. The network uses memistors. ... It is based on the McCulloch–Pitts neuron. It consists of a weight, a bias and a summation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912d76f8",
   "metadata": {},
   "source": [
    "5. What is the constraint of a simple perceptron? Why it may fail with a real-world data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a6281",
   "metadata": {},
   "source": [
    "A perceptron is a simple classifier that takes the weighted sum of the D input feature values (along with an additional constant input value) and outputs + 1 for yes if the result of the weighted sum is greater than some threshold T and outputs 0 for no otherwise. Given data, it is easy to find a threshold and weights for such a perceptron that yield the least error (or cost) on that data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081aced4",
   "metadata": {},
   "source": [
    "6. What is linearly inseparable problem? What is the role of the hidden layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18092e82",
   "metadata": {},
   "source": [
    "⁃ In Single Perceptron / Multi-layer Perceptron(MLP), we only have linear separability because they are composed of input and output layers(some hidden layers in MLP)\n",
    "⁃ For example, AND, OR functions are linearly-separable & XOR function is not linearly separable.\n",
    "⁃ We atleast need one hidden layer to derive a non-linearity separation.\n",
    "⁃ Our RBNN what it does is, it transforms the input signal into another form, which can be then feed into the network to get linear separability.\n",
    "⁃ RBNN is structurally same as perceptron(MLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3563fe",
   "metadata": {},
   "source": [
    "7. Explain XOR problem in case of a simple perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32dc641",
   "metadata": {},
   "source": [
    "Perceptron for XOR:\n",
    "XOR is where if one is 1 and other is 0 but not both. ... A \"single-layer\" perceptron can't implement XOR. The reason is because the classes in XOR are not linearly separable. You cannot draw a straight line to separate the points (0,0),(1,1) from the points (0,1),(1,0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecae891",
   "metadata": {},
   "source": [
    "8. Design a multi-layer perceptron to implement A XOR B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8de98",
   "metadata": {},
   "source": [
    "Implementing logic gates using neural networks help understand the mathematical computation by which a neural network processes its inputs to arrive at a certain output. This neural network will deal with the XOR logic problem. An XOR (exclusive OR gate) is a digital logic gate that gives a true output only when both its inputs differ from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359264b1",
   "metadata": {},
   "source": [
    "9. Explain the single-layer feed forward architecture of ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17606e",
   "metadata": {},
   "source": [
    "In this type of network, we have only two layers, i.e. input layer and output layer but the input layer does not count because no computation is performed in this layer.\n",
    "Output Layer is formed when different weights are applied on input nodes and the cumulative effect per node is taken.\n",
    "After this, the neurons collectively give the output layer to compute the output signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86009e2",
   "metadata": {},
   "source": [
    "10. Explain the competitive network architecture of ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c4bc8",
   "metadata": {},
   "source": [
    "An Artificial Neural Network (ANN) is an information processing paradigm that is inspired by the brain. ... An ANN is configured for a specific application, such as pattern recognition or data classification, through a learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad901e1",
   "metadata": {},
   "source": [
    "11. Consider a multi-layer feed forward neural network. Enumerate and explain steps in the\n",
    "backpropagation algorithm used to train the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94138b96",
   "metadata": {},
   "source": [
    "This network has a hidden layer that is internal to the network and has no direct contact with the external layer.\n",
    "The existence of one or more hidden layers enables the network to be computationally stronger.\n",
    "There are no feedback connections in which outputs of the model are fed back into itself.\n",
    "Multilayer Feed Forward Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a70e7",
   "metadata": {},
   "source": [
    "12. What are the advantages and disadvantages of neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7112b4fb",
   "metadata": {},
   "source": [
    "Here are some advantages of Artificial Neural Networks ( ANN)\n",
    "\n",
    "Storing information on the entire network: Information such as in traditional programming is stored on the entire network, not on a database. The disappearance of a few pieces of information in one place does not restrict the network from functioning. \n",
    "\n",
    "The ability to work with inadequate knowledge: After ANN training, the data may produce output even with incomplete information. The lack of performance here depends on the importance of the missing information. \n",
    "\n",
    "It has fault tolerance:  Corruption of one or more cells of ANN does not prevent it from generating output. This feature makes the networks fault-tolerant. \n",
    "\n",
    "Having a distributed memory: For ANN to be able to learn, it is necessary to determine the examples and to teach the network according to the desired output by showing these examples to the network. The network's progress is directly proportional to the selected instances, and if the event can not be shown to the network in all its aspects, the network can produce incorrect output \n",
    "\n",
    "Gradual corruption:  A network slows over time and undergoes relative degradation. The network problem does not immediately corrode.\n",
    "\n",
    "Ability to train machine: Artificial neural networks learn events and make decisions by commenting on similar events. \n",
    "\n",
    " Parallel processing ability:  Artificial neural networks have numerical strength that can perform more than one job at the same time. \n",
    "\n",
    "Disadvantages of Artificial Neural Networks (ANN)\n",
    "\n",
    "Hardware dependence:  Artificial neural networks require processors with parallel processing power, by their structure. For this reason, the realization of the equipment is dependent. \n",
    "\n",
    "Unexplained functioning of the network: This is the most important problem of ANN. When ANN gives a probing solution, it does not give a clue as to why and how. This reduces trust in the network. \n",
    "\n",
    "Assurance of proper network structure:  There is no specific rule for determining the structure of artificial neural networks. The appropriate network structure is achieved through experience and trial and error. \n",
    "\n",
    "The difficulty of showing the problem to the network:  ANNs can work with numerical information. Problems have to be translated into numerical values before being introduced to ANN. The display mechanism to be determined here will directly influence the performance of the network. This depends on the user's ability. \n",
    "\n",
    "The duration of the network is unknown: The network is reduced to a certain value of the error on the sample means that the training has been completed. This value does not give us optimum results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a356f",
   "metadata": {},
   "source": [
    "13. Write short notes on any two of the following:\n",
    "\n",
    "1. Biological neuron\n",
    "2. ReLU function\n",
    "3. Single-layer feed forward ANN\n",
    "4. Gradient descent\n",
    "5. Recurrent networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed62109",
   "metadata": {},
   "source": [
    "<h1>Biological Neurons</h1>\n",
    "Typical biological neurons are individual cells, each composed of the main body of the cell along with many tendrils that extend from that body. The body, or soma, houses the machinery for maintaining basic cell functions and energy processing (e.g., the DNA-containing nucleus, and organelles for building proteins and processing sugar and oxygen). There are two types of tendrils: dendrites, which receive information from other neurons and bring it to the cell body, and axons, which send information from the cell body to other neurons.\n",
    "\n",
    "<h1>ReLU function</h1>\n",
    "ReLU stands for rectified linear activation unit and is considered one of the few milestones in the deep learning revolution. It is simple yet really better than its predecessor activation functions such as sigmoid or tanh.\n",
    "\n",
    "<h1>Single-layer feed forward ANN</h1>\n",
    "In this type of network, we have only two layers, i.e. input layer and output layer but the input layer does not count because no computation is performed in this layer.\n",
    "Output Layer is formed when different weights are applied on input nodes and the cumulative effect per node is taken.\n",
    "After this, the neurons collectively give the output layer to compute the output signals.\n",
    "\n",
    "<h1>Gradient descent</h1>\n",
    "Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent.\n",
    "\n",
    "<h1>Recurrent networks</h1>\n",
    "Recurrent Neural Network(RNN) are a type of Neural Network where the output from previous step are fed as input to the current step. In traditional neural networks, all the inputs and outputs are independent of each other, but in cases like when it is required to predict the next word of a sentence, the previous words are required and hence there is a need to remember the previous words. Thus RNN came into existence, which solved this issue with the help of a Hidden Layer. The main and most important feature of RNN is Hidden state, which remembers some information about a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe20c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
