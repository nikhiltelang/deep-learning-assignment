{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cee5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What are the advantages of a CNN over a fully connected DNN for image classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575f956e",
   "metadata": {},
   "source": [
    "The main advantage of CNN compared to its predecessors is that it automatically detects the important features without any human supervision. For example, given many pictures of cats and dogs it learns distinctive features for each class by itself. CNN is also computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15edf489",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of\n",
    "2, and &quot;same&quot; padding. The lowest layer outputs 100 feature maps, the middle one outputs\n",
    "200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels.\n",
    "What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much\n",
    "RAM will this network require when making a prediction for a single instance? What about when\n",
    "training on a mini-batch of 50 images?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7af9a9",
   "metadata": {},
   "source": [
    "parameters\n",
    "\n",
    "first convolutional layer kernel-size and RGB channels, plus bias: 3 * 3 * 3 + 1 = 28 output feature maps is 100: 28 * 100 = 2800\n",
    "second convolutional layer kernel-size and last feature maps, plus bias: 3 * 3 * 100 + 1 = 901 output feature maps is 200: 901 * 200 = 180200\n",
    "third convolutional layers kernel-size and last feautre maps, plus bias: 3 * 3 * 200 + 1 =1801 output feautre maps is 400: 1801 * 400 = 720400\n",
    "Total parameters is 2800 + 180200 + 720400 = 903400\n",
    "\n",
    "memories since 32-bit is 4 bytes\n",
    "\n",
    "first convolutional layer one feature map size: 100 * 150 = 15000 total output: 15000 * 100 = 1,500,000\n",
    "second convolutional layer one feature map size: 50 * 75 = 3,750 total output: 3750 * 200 = 750,000\n",
    "third convolutional layer one feature map size: 25 * 38 = 950 total ouput: 950 * 400 = 380, 000\n",
    "(1,500,000 + 750,000 + 380,000) * 4 / 1024 /1024 = 10.032 (MB) 903400 * 4 / 1024 / 1024 = 3.44 (MB) 10.032+ 3.44=13.47(MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. If your GPU runs out of memory while training a CNN, what are five things you could try to\n",
    "solve the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f20a8d9",
   "metadata": {},
   "source": [
    "reduce mini-batch size\n",
    "reduce dimensionality using a larger stride in one or more layers\n",
    "remove one or more layers\n",
    "using 16-bits instead of 32-bit floats\n",
    "distributed the cnn across multiple devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Why would you want to add a max pooling layer rather than a convolutional layer with the\n",
    "same stride?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406fa958",
   "metadata": {},
   "source": [
    "When you can extract some features, it is advisable to do Max Pooling. It’s not advised to do Max pooling in the initial stages of the Convolutional Neural Network as the Kernels would be at the stage of extracting edges and gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. When would you want to add a local response normalization layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e72e2d",
   "metadata": {},
   "source": [
    "Local Response Normalization is a normalization layer that implements the idea of lateral inhibition. Lateral inhibition is a concept in neurobiology that refers to the phenomenon of an excited neuron inhibiting its neighbours: this leads to a peak in the form of a local maximum, creating contrast in that area and increasing sensory perception. In practice, we can either normalize within the same channel or normalize across channels when we apply LRN to convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Can you name the main innovations in AlexNet, compared to LeNet-5? What about the main\n",
    "innovations in GoogLeNet, ResNet, SENet, and Xception?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7814910",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet\n",
    "it is much larger and deeper\n",
    "stacks convolutional layer directly on top of each convlutional layer\n",
    "\n",
    "GooLeNet\n",
    "introduce a inception modules, which make it possible to have much deeper net than previous network\n",
    "\n",
    "ResNet\n",
    "introduce a skip connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. What is a fully convolutional network? How can you convert a dense layer into a\n",
    "convolutional layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98645f",
   "metadata": {},
   "source": [
    " FCN is a network that does not contain any “Dense” layers (as in traditional CNNs) instead it contains 1x1 convolutions that perform the task of fully connected layers (Dense layers). Though the absence of dense layers makes it possible to feed in variable inputs, there are a couple of techniques that enable us to use dense layers while cherishing variable input dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8324ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. What is the main technical difficulty of semantic segmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c695d7",
   "metadata": {},
   "source": [
    "However, semantic segmentation also has a major problem specific difficulty. This difficulty is caused by an ambiguity of boundaries in image space, especially for thin objects such as poles, similar looking objects such as a road and a sidewalk and far away objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a24045",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of loading the fashion mnist dataset\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import fashion_mnist\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Use transfer learning for large image classification, going through these steps:\n",
    "a. Create a training set containing at least 100 images per class. For example, you could\n",
    "classify your own pictures based on the location (beach, mountain, city, etc.), or\n",
    "alternatively you can use an existing dataset (e.g., from TensorFlow Datasets).\n",
    "b. Split it into a training set, a validation set, and a test set.\n",
    "c. Build the input pipeline, including the appropriate preprocessing operations, and\n",
    "optionally add data augmentation.\n",
    "d. Fine-tune a pretrained model on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cc7659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e382209b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
